# ğŸ§  Local Legal AI

A fully private, self-hosted LLM-powered assistant tailored for **law firms**. This platform enables secure, high-performance legal document Q&A using **open-source models**, **vector search**, and **automation workflows**â€”all without sending a single byte to third-party APIs.

## ğŸš€ Features

- ğŸ” **Private Deployment** â€” No OpenAI/Anthropic dependencies
- ğŸ§¾ **Legal Document Q&A** â€” Use RAG (Retrieval-Augmented Generation) with case files, contracts, and statutes
- âš¡ï¸ **Fast Inference** â€” Powered by [LLaMA 3](https://ai.meta.com/llama/) via [vLLM](https://github.com/vllm-project/vllm)
- ğŸ“š **Vector Search** â€” Efficient and scalable storage of embeddings using [ChromaDB](https://www.trychroma.com/)
- ğŸ’¬ **Modern Chat UI** â€” Streamlit-based frontend for lawyers and staff to ask natural language questions
- ğŸ” **Automation** â€” Built-in [n8n](https://n8n.io/) to handle file drops, Slack alerts, and data flows
- ğŸ›¡ **Audit Logging & Access Control** â€” Secure everything with JWT, IP whitelisting, and activity logs

## ğŸ§± Architecture

```
User â†” Streamlit UI â†” FastAPI Backend â†” RAG Pipeline â†” ChromaDB â†” Embedded Legal Docs
                                          â†•
                                    vLLM (LLaMA 3)
                                          â†•
                              Secure GPU Host (CoreWeave / On-Prem)
```

## ğŸ“‚ Project Structure

```
local-legal-ai/
â”œâ”€â”€ backend/                  # FastAPI backend and RAG logic
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ auth.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ embedder.py
â”‚   â””â”€â”€ rag_pipeline.py
â”œâ”€â”€ frontend/                 # Streamlit-based UI
â”‚   â””â”€â”€ streamlit_app.py
â”œâ”€â”€ vector_store/             # ChromaDB setup
â”‚   â””â”€â”€ chromadb_setup.py
â”œâ”€â”€ model/                    # LLaMA 3 launcher via vLLM
â”‚   â””â”€â”€ vllm_launcher.sh
â”œâ”€â”€ workflows/n8n/           # Automation flows
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â””â”€â”€ workflows.json
â”œâ”€â”€ security/                # Access logging and controls
â”‚   â””â”€â”€ audit_log.py
â”œâ”€â”€ docker-compose.yml       # Orchestration file
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ .env                     # Secrets and config
â””â”€â”€ README.md                # This file
```

## ğŸ§ª Setup Instructions

### 1. Clone and Prepare

```bash
git clone https://github.com/your-org/local-legal-ai.git
cd local-legal-ai
python3 -m venv venv && source venv/bin/activate
pip install -r requirements.txt
```

### 2. Configure Environment

Fill in `.env` with your secrets:

```env
SECRET_KEY=your-secret-key
MODEL_ENDPOINT=http://localhost:8001
```

### 3. Launch LLaMA 3 with vLLM

```bash
bash model/vllm_launcher.sh
```

You'll need access to A100-class GPUs or rent from a provider like [CoreWeave](https://www.coreweave.com/).

### 4. Start Services

```bash
docker-compose up --build
```

This runs:
- FastAPI backend
- ChromaDB vector store
- n8n automation engine
- Streamlit frontend

## ğŸ’¡ Example Use Cases

- ğŸ” **Ask questions** about litigation filings and get citations
- ğŸ“„ **Summarize** long legal contracts or court rulings
- ğŸ“¥ **Upload** new PDFs to a folder and trigger ingestion automatically via n8n
- ğŸ” **Keep** all client and case data 100% private

## ğŸ›¡ Security Best Practices

- **JWT authentication** (configurable in `auth.py`)
- **IP whitelisting** and role-based access controls
- **Full audit logs** of queries in `security/audit_log.py`
- **No outbound API calls** to third-party LLMs

## ğŸ§© Stack Highlights

| Layer        | Tool/Library          |
|-------------|-----------------------|
| Model        | LLaMA 3 (70B) + vLLM  |
| Vector Store | ChromaDB              |
| RAG Engine   | LlamaIndex            |
| Backend      | FastAPI (JWT-secured) |
| Frontend     | Streamlit             |
| Automation   | n8n                   |
| Security     | Audit logging, JWT    |

## ğŸ“Œ Roadmap

- [ ] Add document classification before embedding
- [ ] Multi-user roles & access management
- [ ] UI for document browsing & retrieval
- [ ] Dockerized GPU inference node
